{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Install packages","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nsys.path.append(\"../input/segmentation-models-pytorch/segmentation_models.pytorch-0.2.1\")\nsys.path.append(\"../input/pretrainedmodels/pretrainedmodels-0.7.4\")\nsys.path.append(\"../input/efficientnet-pytorch/EfficientNet-PyTorch-master\")\n\n!pip install ../input/mmdetection/addict-2.4.0-py3-none-any.whl > /dev/null\n!pip install ../input/mmdetection/yapf-0.31.0-py2.py3-none-any.whl > /dev/null\n!pip install ../input/mmdetection/terminaltables-3.1.0-py3-none-any.whl > /dev/null\n!pip install ../input/mmdetection/einops* > /dev/null\n!pip install ../input/mmdetection/mmcv_full-1.3.17-cp37-cp37m-linux_x86_64.whl > /dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-09T08:30:06.836975Z","iopub.execute_input":"2022-05-09T08:30:06.837379Z","iopub.status.idle":"2022-05-09T08:31:10.755491Z","shell.execute_reply.started":"2022-05-09T08:30:06.837271Z","shell.execute_reply":"2022-05-09T08:31:10.754348Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Install mmsegmentation \n\nThis is from my own [mmseg github repo](https://github.com/CarnoZhao/Kaggle-UWMGIT) (leave a star if you like it!)\n\nI have integrated `segmentation_models_pytorch` in this version of `mmsegmentation`. Although `segmentation_models_pytorch`'s simple Unet performs better than some models of `mmsegmentation`, anyway, `mmsegmentation` is still a good library for segmentation task when you want to compare various models in a unified training pipeline.\n\nI only hard-coded `smp.Unet` in `./mmseg/models/segmentors/smp_models.py`. You can add more `smp` models in it!","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/CarnoZhao/Kaggle-UWMGIT && cd Kaggle-UWMGIT && pip install -e .","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:31:10.757832Z","iopub.execute_input":"2022-05-09T08:31:10.758125Z","iopub.status.idle":"2022-05-09T08:31:29.588654Z","shell.execute_reply.started":"2022-05-09T08:31:10.758073Z","shell.execute_reply":"2022-05-09T08:31:29.587540Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'Kaggle-UWMGIT'...\nremote: Enumerating objects: 5361, done.\u001b[K\nremote: Counting objects: 100% (5361/5361), done.\u001b[K\nremote: Compressing objects: 100% (1126/1126), done.\u001b[K\nremote: Total 5361 (delta 4185), reused 5361 (delta 4185), pack-reused 0\u001b[K\nReceiving objects: 100% (5361/5361), 5.03 MiB | 8.24 MiB/s, done.\nResolving deltas: 100% (4185/4185), done.\nObtaining file:///kaggle/working/Kaggle-UWMGIT\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from mmsegmentation==0.19.0) (3.5.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mmsegmentation==0.19.0) (1.21.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from mmsegmentation==0.19.0) (21.3)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.7/site-packages (from mmsegmentation==0.19.0) (3.2.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.19.0) (4.30.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.19.0) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.19.0) (1.4.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.19.0) (9.0.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.19.0) (2.8.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mmsegmentation==0.19.0) (3.0.7)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from prettytable->mmsegmentation==0.19.0) (4.11.3)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prettytable->mmsegmentation==0.19.0) (0.2.5)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->mmsegmentation==0.19.0) (4.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==0.19.0) (1.16.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->prettytable->mmsegmentation==0.19.0) (3.7.0)\nInstalling collected packages: mmsegmentation\n  Running setup.py develop for mmsegmentation\nSuccessfully installed mmsegmentation-0.19.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3. Prepare data","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nfrom PIL import Image\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:31:29.592728Z","iopub.execute_input":"2022-05-09T08:31:29.593003Z","iopub.status.idle":"2022-05-09T08:31:29.886617Z","shell.execute_reply.started":"2022-05-09T08:31:29.592972Z","shell.execute_reply":"2022-05-09T08:31:29.885632Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 Read csv and extract meta info","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/train.csv\")\ndf_train = df_train.sort_values([\"id\", \"class\"]).reset_index(drop = True)\ndf_train[\"patient\"] = df_train.id.apply(lambda x: x.split(\"_\")[0])\ndf_train[\"days\"] = df_train.id.apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\n\nall_image_files = sorted(glob.glob(\"../input/uw-madison-gi-tract-image-segmentation/train/*/*/scans/*.png\"), key = lambda x: x.split(\"/\")[3] + \"_\" + x.split(\"/\")[5])\nsize_x = [int(os.path.basename(_)[:-4].split(\"_\")[-4]) for _ in all_image_files]\nsize_y = [int(os.path.basename(_)[:-4].split(\"_\")[-3]) for _ in all_image_files]\nspacing_x = [float(os.path.basename(_)[:-4].split(\"_\")[-2]) for _ in all_image_files]\nspacing_y = [float(os.path.basename(_)[:-4].split(\"_\")[-1]) for _ in all_image_files]\ndf_train[\"image_files\"] = np.repeat(all_image_files, 3)\ndf_train[\"spacing_x\"] = np.repeat(spacing_x, 3)\ndf_train[\"spacing_y\"] = np.repeat(spacing_y, 3)\ndf_train[\"size_x\"] = np.repeat(size_x, 3)\ndf_train[\"size_y\"] = np.repeat(size_y, 3)\ndf_train[\"slice\"] = np.repeat([int(os.path.basename(_)[:-4].split(\"_\")[-5]) for _ in all_image_files], 3)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:31:29.889126Z","iopub.execute_input":"2022-05-09T08:31:29.889577Z","iopub.status.idle":"2022-05-09T08:31:35.008647Z","shell.execute_reply.started":"2022-05-09T08:31:29.889530Z","shell.execute_reply":"2022-05-09T08:31:35.007544Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                              id        class segmentation  patient  \\\n0       case101_day20_slice_0001  large_bowel          NaN  case101   \n1       case101_day20_slice_0001  small_bowel          NaN  case101   \n2       case101_day20_slice_0001      stomach          NaN  case101   \n3       case101_day20_slice_0002  large_bowel          NaN  case101   \n4       case101_day20_slice_0002  small_bowel          NaN  case101   \n...                          ...          ...          ...      ...   \n115483    case9_day22_slice_0143  small_bowel          NaN    case9   \n115484    case9_day22_slice_0143      stomach          NaN    case9   \n115485    case9_day22_slice_0144  large_bowel          NaN    case9   \n115486    case9_day22_slice_0144  small_bowel          NaN    case9   \n115487    case9_day22_slice_0144      stomach          NaN    case9   \n\n                 days                                        image_files  \\\n0       case101_day20  ../input/uw-madison-gi-tract-image-segmentatio...   \n1       case101_day20  ../input/uw-madison-gi-tract-image-segmentatio...   \n2       case101_day20  ../input/uw-madison-gi-tract-image-segmentatio...   \n3       case101_day20  ../input/uw-madison-gi-tract-image-segmentatio...   \n4       case101_day20  ../input/uw-madison-gi-tract-image-segmentatio...   \n...               ...                                                ...   \n115483    case9_day22  ../input/uw-madison-gi-tract-image-segmentatio...   \n115484    case9_day22  ../input/uw-madison-gi-tract-image-segmentatio...   \n115485    case9_day22  ../input/uw-madison-gi-tract-image-segmentatio...   \n115486    case9_day22  ../input/uw-madison-gi-tract-image-segmentatio...   \n115487    case9_day22  ../input/uw-madison-gi-tract-image-segmentatio...   \n\n        spacing_x  spacing_y  size_x  size_y  slice  \n0             1.5        1.5     266     266      6  \n1             1.5        1.5     266     266      6  \n2             1.5        1.5     266     266      6  \n3             1.5        1.5     266     266     82  \n4             1.5        1.5     266     266     82  \n...           ...        ...     ...     ...    ...  \n115483        1.5        1.5     360     310     93  \n115484        1.5        1.5     360     310     93  \n115485        1.5        1.5     360     310    135  \n115486        1.5        1.5     360     310    135  \n115487        1.5        1.5     360     310    135  \n\n[115488 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n      <th>segmentation</th>\n      <th>patient</th>\n      <th>days</th>\n      <th>image_files</th>\n      <th>spacing_x</th>\n      <th>spacing_y</th>\n      <th>size_x</th>\n      <th>size_y</th>\n      <th>slice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>case101_day20_slice_0001</td>\n      <td>large_bowel</td>\n      <td>NaN</td>\n      <td>case101</td>\n      <td>case101_day20</td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>266</td>\n      <td>266</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>case101_day20_slice_0001</td>\n      <td>small_bowel</td>\n      <td>NaN</td>\n      <td>case101</td>\n      <td>case101_day20</td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>266</td>\n      <td>266</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>case101_day20_slice_0001</td>\n      <td>stomach</td>\n      <td>NaN</td>\n      <td>case101</td>\n      <td>case101_day20</td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>266</td>\n      <td>266</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>case101_day20_slice_0002</td>\n      <td>large_bowel</td>\n      <td>NaN</td>\n      <td>case101</td>\n      <td>case101_day20</td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>266</td>\n      <td>266</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>case101_day20_slice_0002</td>\n      <td>small_bowel</td>\n      <td>NaN</td>\n      <td>case101</td>\n      <td>case101_day20</td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>266</td>\n      <td>266</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115483</th>\n      <td>case9_day22_slice_0143</td>\n      <td>small_bowel</td>\n      <td>NaN</td>\n      <td>case9</td>\n      <td>case9_day22</td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>360</td>\n      <td>310</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>115484</th>\n      <td>case9_day22_slice_0143</td>\n      <td>stomach</td>\n      <td>NaN</td>\n      <td>case9</td>\n      <td>case9_day22</td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>360</td>\n      <td>310</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>115485</th>\n      <td>case9_day22_slice_0144</td>\n      <td>large_bowel</td>\n      <td>NaN</td>\n      <td>case9</td>\n      <td>case9_day22</td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>360</td>\n      <td>310</td>\n      <td>135</td>\n    </tr>\n    <tr>\n      <th>115486</th>\n      <td>case9_day22_slice_0144</td>\n      <td>small_bowel</td>\n      <td>NaN</td>\n      <td>case9</td>\n      <td>case9_day22</td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>360</td>\n      <td>310</td>\n      <td>135</td>\n    </tr>\n    <tr>\n      <th>115487</th>\n      <td>case9_day22_slice_0144</td>\n      <td>stomach</td>\n      <td>NaN</td>\n      <td>case9</td>\n      <td>case9_day22</td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>1.5</td>\n      <td>1.5</td>\n      <td>360</td>\n      <td>310</td>\n      <td>135</td>\n    </tr>\n  </tbody>\n</table>\n<p>115488 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 3.2 Make mmseg-format data (2.5D by default)\n\n\nHere, I used 2.5d data with stride=2. Thanks this good trick from [https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-stride-2-data](https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-stride-2-data)","metadata":{}},{"cell_type":"code","source":"def rle_decode(mask_rle, shape):\n    s = np.array(mask_rle.split(), dtype=int)\n    starts, lengths = s[0::2] - 1, s[1::2]\n    ends = starts + lengths\n    h, w = shape\n    img = np.zeros((h * w,), dtype = np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = 1\n    return img.reshape(shape)\n\n!mkdir -p ./mmseg_train/{images,labels,splits}\nfor day, group in tqdm(df_train.groupby(\"days\")):\n    patient = group.patient.iloc[0]\n    imgs = []\n    msks = []\n    file_names = []\n    for file_name in group.image_files.unique():\n        img = cv2.imread(file_name, cv2.IMREAD_ANYDEPTH)\n        segms = group.loc[group.image_files == file_name]\n        masks = {}\n        for segm, label in zip(segms.segmentation, segms[\"class\"]):\n            if not pd.isna(segm):\n                mask = rle_decode(segm, img.shape[:2])\n                masks[label] = mask\n            else:\n                masks[label] = np.zeros(img.shape[:2], dtype = np.uint8)\n        masks = np.stack([masks[k] for k in sorted(masks)], -1)\n        imgs.append(img)\n        msks.append(masks)\n        \n    imgs = np.stack(imgs, 0)\n    msks = np.stack(msks, 0)\n    for i in range(msks.shape[0]):\n        img = imgs[[max(0, i - 2), i, min(imgs.shape[0] - 1, i + 2)]].transpose(1,2,0) # 2.5d data\n        msk = msks[i]\n        new_file_name = f\"{day}_{i}.png\"\n        cv2.imwrite(f\"./mmseg_train/images/{new_file_name}\", img)\n        cv2.imwrite(f\"./mmseg_train/labels/{new_file_name}\", msk)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:36:20.889358Z","iopub.execute_input":"2022-05-09T08:36:20.890359Z","iopub.status.idle":"2022-05-09T08:47:22.970489Z","shell.execute_reply.started":"2022-05-09T08:36:20.890318Z","shell.execute_reply":"2022-05-09T08:47:22.969389Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/274 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67f58495edd84f649612c84e7a219fba"}},"metadata":{}}]},{"cell_type":"markdown","source":"## 3.3 Make fold splits","metadata":{}},{"cell_type":"code","source":"all_image_files = glob.glob(\"./mmseg_train/images/*\")\npatients = [os.path.basename(_).split(\"_\")[0] for _ in all_image_files]\n\n\nfrom sklearn.model_selection import GroupKFold\n\nsplit = list(GroupKFold(5).split(patients, groups = patients))\n\nfor fold, (train_idx, valid_idx) in enumerate(split):\n    with open(f\"./mmseg_train/splits/fold_{fold}.txt\", \"w\") as f:\n        for idx in train_idx:\n            f.write(os.path.basename(all_image_files[idx])[:-4] + \"\\n\")\n    with open(f\"./mmseg_train/splits/holdout_{fold}.txt\", \"w\") as f:\n        for idx in valid_idx:\n            f.write(os.path.basename(all_image_files[idx])[:-4] + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:47:56.800580Z","iopub.execute_input":"2022-05-09T08:47:56.800946Z","iopub.status.idle":"2022-05-09T08:47:58.596427Z","shell.execute_reply.started":"2022-05-09T08:47:56.800898Z","shell.execute_reply":"2022-05-09T08:47:58.595390Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training\n\n## 4.1 Make config\n\nThis is only **a simple baseline**, you can change anything in it\n\nFrom my own experiment, when using larger backbone, larger image size and more augs, the public score will be easily exceed 0.865.\n\nHere, I only train for 1k iters. **More iters are required to get a valid score**.\n\nI have made a single model submission scored 0.878 using this training pipeline!","metadata":{}},{"cell_type":"code","source":"%%bash\n\ncat <<EOT >> ./Kaggle-UWMGIT/config.py\nnum_classes = 3\n\n# model settings\nnorm_cfg = dict(type='SyncBN', requires_grad=True)\nloss = [\n    dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n]\nmodel = dict(\n    type='SMPUnet',\n    backbone=dict(\n        type='timm-efficientnet-b0',\n        pretrained=\"imagenet\"\n    ),\n    decode_head=dict(\n        num_classes=num_classes,\n        align_corners=False,\n        loss_decode=loss\n    ),\n    # model training and testing settings\n    train_cfg=dict(),\n    test_cfg=dict(mode=\"whole\", multi_label=True))\n\n# dataset settings\ndataset_type = 'CustomDataset'\ndata_root = '../mmseg_train/'\nclasses = ['large_bowel', 'small_bowel', 'stomach']\npalette = [[0,0,0], [128,128,128], [255,255,255]]\nimg_norm_cfg = dict(mean=[0,0,0], std=[1,1,1], to_rgb=True)\nsize = 256\nalbu_train_transforms = [\n    dict(type='RandomBrightnessContrast', p=0.5),\n]\ntrain_pipeline = [\n    dict(type='LoadImageFromFile', to_float32=True, color_type='unchanged', max_value='max'),\n    dict(type='LoadAnnotations'),\n    dict(type='Resize', img_scale=(size, size), keep_ratio=True),\n    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n    dict(type='Albu', transforms=albu_train_transforms),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile', to_float32=True, color_type='unchanged', max_value='max'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(size, size),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\ndata = dict(\n    samples_per_gpu=8,\n    workers_per_gpu=4,\n    train=dict(\n        type=dataset_type,\n        multi_label=True,\n        data_root=data_root,\n        img_dir='images',\n        ann_dir='labels',\n        img_suffix=\".png\",\n        seg_map_suffix='.png',\n        split=\"splits/fold_0.txt\",\n        classes=classes,\n        palette=palette,\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,\n        multi_label=True,\n        data_root=data_root,\n        img_dir='images',\n        ann_dir='labels',\n        img_suffix=\".png\",\n        seg_map_suffix='.png',\n        split=\"splits/holdout_0.txt\",\n        classes=classes,\n        palette=palette,\n        pipeline=test_pipeline),\n    test=dict(\n        type=dataset_type,\n        multi_label=True,\n        data_root=data_root,\n        test_mode=True,\n        img_dir='test/images',\n        ann_dir='test/labels',\n        img_suffix=\".jpg\",\n        seg_map_suffix='.png',\n        classes=classes,\n        palette=palette,\n        pipeline=test_pipeline))\n\n# yapf:disable\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='CustomizedTextLoggerHook', by_epoch=False),\n    ])\n# yapf:enable\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\ncudnn_benchmark = True\n\ntotal_iters = 1\n# optimizer\noptimizer = dict(type='AdamW', lr=1e-3, betas=(0.9, 0.999), weight_decay=0.05)\noptimizer_config = dict(type='Fp16OptimizerHook', loss_scale='dynamic')\n# learning policy\nlr_config = dict(policy='poly',\n                 warmup='linear',\n                 warmup_iters=500,\n                 warmup_ratio=1e-6,\n                 power=1.0, min_lr=0.0, by_epoch=False)\n# runtime settings\nfind_unused_parameters=True\nrunner = dict(type='IterBasedRunner', max_iters=int(total_iters * 1000))\ncheckpoint_config = dict(by_epoch=False, interval=int(total_iters * 1000), save_optimizer=False)\nevaluation = dict(by_epoch=False, interval=min(5000, int(total_iters * 1000)), metric=['imDice', 'mDice'], pre_eval=True)\nfp16 = dict()\n\nwork_dir = f'./work_dirs/tract/baseline'\nEOT","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:58:48.435613Z","iopub.execute_input":"2022-05-09T08:58:48.436652Z","iopub.status.idle":"2022-05-09T08:58:48.475306Z","shell.execute_reply.started":"2022-05-09T08:58:48.436615Z","shell.execute_reply":"2022-05-09T08:58:48.474046Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# 4.2 Let's start training","metadata":{}},{"cell_type":"code","source":"# reinstall for inner bash usage\n!cp -r ../input/segmentation-models-pytorch/segmentation_models.pytorch-0.2.1 ./ && cd segmentation_models.pytorch-0.2.1  && pip install -e .\n!cp -r ../input/timm-pytorch-image-models/pytorch-image-models-master ./ && cd pytorch-image-models-master  && pip install -e .","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:54:26.937687Z","iopub.execute_input":"2022-05-09T08:54:26.938027Z","iopub.status.idle":"2022-05-09T08:55:02.605569Z","shell.execute_reply.started":"2022-05-09T08:54:26.937993Z","shell.execute_reply":"2022-05-09T08:55:02.604436Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Obtaining file:///kaggle/working/segmentation_models.pytorch-0.2.1\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.10.1)\nCollecting pretrainedmodels==0.7.4\n  Using cached pretrainedmodels-0.7.4-py3-none-any.whl\nRequirement already satisfied: efficientnet-pytorch==0.6.3 in /opt/conda/lib/python3.7/site-packages (from segmentation-models-pytorch==0.2.1) (0.6.3)\nCollecting timm==0.4.12\n  Using cached timm-0.4.12-py3-none-any.whl (376 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.2.1) (1.9.1)\nRequirement already satisfied: munch in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (2.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (4.63.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (1.21.6)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch==0.2.1) (9.0.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation-models-pytorch==0.2.1) (4.2.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch==0.2.1) (1.16.0)\nInstalling collected packages: timm, pretrainedmodels, segmentation-models-pytorch\n  Attempting uninstall: timm\n    Found existing installation: timm 0.5.4\n    Uninstalling timm-0.5.4:\n      Successfully uninstalled timm-0.5.4\n  Running setup.py develop for segmentation-models-pytorch\nSuccessfully installed pretrainedmodels-0.7.4 segmentation-models-pytorch-0.2.1 timm-0.4.12\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mObtaining file:///kaggle/working/pytorch-image-models-master\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm==0.5.4) (1.9.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.5.4) (0.10.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.5.4) (4.2.0)\nRequirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.5.4) (9.0.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.5.4) (1.21.6)\nInstalling collected packages: timm\n  Attempting uninstall: timm\n    Found existing installation: timm 0.4.12\n    Uninstalling timm-0.4.12:\n      Successfully uninstalled timm-0.4.12\n  Running setup.py develop for timm\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsegmentation-models-pytorch 0.2.1 requires timm==0.4.12, but you have timm 0.5.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed timm-0.5.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"%%bash\n\ncd Kaggle-UWMGIT\n\npython ./tools/train.py ./config.py --gpu-ids 0","metadata":{"execution":{"iopub.status.busy":"2022-05-09T09:03:53.745587Z","iopub.execute_input":"2022-05-09T09:03:53.747416Z","iopub.status.idle":"2022-05-09T09:13:36.689906Z","shell.execute_reply.started":"2022-05-09T09:03:53.747345Z","shell.execute_reply":"2022-05-09T09:13:36.689136Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"[>>>>>>>>>>>>>>>>>>>>>>>>>>] 7664/7664, 21.7 task/s, elapsed: 354s, ETA:     0s","output_type":"stream"}]},{"cell_type":"markdown","source":"# 5. Inferencing\n\n## 5.1 Load trained models","metadata":{}},{"cell_type":"code","source":"sys.path.append('./Kaggle-UWMGIT')\nfrom mmseg.apis import init_segmentor, inference_segmentor\nfrom mmcv.utils import config\n\ncfgs = [\n    \"./Kaggle-UWMGIT/work_dirs/tract/baseline/config.py\",\n]\n\nckpts = [\n    \"./Kaggle-UWMGIT/work_dirs/tract/baseline/latest.pth\",\n]\n\nmodels = []\nfor cfg, ckpt in zip(cfgs, ckpts):\n    cfg = config.Config.fromfile(cfg)\n    cfg.model.backbone.pretrained = None\n    cfg.model.test_cfg.logits = True\n    cfg.data.test.pipeline[1].transforms.insert(2, dict(type=\"Normalize\", mean=[0,0,0], std=[1,1,1], to_rgb=False))\n\n    model = init_segmentor(cfg, ckpt)\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T09:15:54.574088Z","iopub.execute_input":"2022-05-09T09:15:54.574832Z","iopub.status.idle":"2022-05-09T09:16:15.155125Z","shell.execute_reply.started":"2022-05-09T09:15:54.574788Z","shell.execute_reply":"2022-05-09T09:16:15.154002Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"load checkpoint from local path: ./Kaggle-UWMGIT/work_dirs/tract/baseline/latest.pth\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 5.2 Make test submission csv","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport glob\nfrom tqdm.auto import tqdm\nfrom scipy.ndimage import binary_closing, binary_opening, measurements\n\ndef rle_encode(img):\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\nclasses = ['large_bowel', 'small_bowel', 'stomach']\ndata_dir = \"../input/uw-madison-gi-tract-image-segmentation/\"\ntest_dir = os.path.join(data_dir, \"test\")\nsub = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"))\ntest_images = glob.glob(os.path.join(test_dir, \"**\", \"*.png\"), recursive = True)\n\nif len(test_images) == 0:\n    test_dir = os.path.join(data_dir, \"train\")\n    sub = pd.read_csv(os.path.join(data_dir, \"train.csv\"))[[\"id\", \"class\"]].iloc[:100 * 3]\n    sub[\"predicted\"] = \"\"\n    test_images = glob.glob(os.path.join(test_dir, \"**\", \"*.png\"), recursive = True)\n    \nid2img = {_.rsplit(\"/\", 4)[2] + \"_\" + \"_\".join(_.rsplit(\"/\", 4)[4].split(\"_\")[:2]): _ for _ in test_images}\nsub[\"file_name\"] = sub.id.map(id2img)\nsub[\"days\"] = sub.id.apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\nfname2index = {f + c: i for f, c, i in zip(sub.file_name, sub[\"class\"], sub.index)}\nsub","metadata":{"execution":{"iopub.status.busy":"2022-05-09T09:16:22.372231Z","iopub.execute_input":"2022-05-09T09:16:22.372768Z","iopub.status.idle":"2022-05-09T09:16:27.031128Z","shell.execute_reply.started":"2022-05-09T09:16:22.372730Z","shell.execute_reply":"2022-05-09T09:16:27.030078Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"                           id        class predicted  \\\n0    case123_day20_slice_0001  large_bowel             \n1    case123_day20_slice_0001  small_bowel             \n2    case123_day20_slice_0001      stomach             \n3    case123_day20_slice_0002  large_bowel             \n4    case123_day20_slice_0002  small_bowel             \n..                        ...          ...       ...   \n295  case123_day20_slice_0099  small_bowel             \n296  case123_day20_slice_0099      stomach             \n297  case123_day20_slice_0100  large_bowel             \n298  case123_day20_slice_0100  small_bowel             \n299  case123_day20_slice_0100      stomach             \n\n                                             file_name           days  \n0    ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n1    ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n2    ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n3    ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n4    ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n..                                                 ...            ...  \n295  ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n296  ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n297  ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n298  ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n299  ../input/uw-madison-gi-tract-image-segmentatio...  case123_day20  \n\n[300 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n      <th>predicted</th>\n      <th>file_name</th>\n      <th>days</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>case123_day20_slice_0001</td>\n      <td>large_bowel</td>\n      <td></td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>case123_day20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>case123_day20_slice_0001</td>\n      <td>small_bowel</td>\n      <td></td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>case123_day20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>case123_day20_slice_0001</td>\n      <td>stomach</td>\n      <td></td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>case123_day20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>case123_day20_slice_0002</td>\n      <td>large_bowel</td>\n      <td></td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>case123_day20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>case123_day20_slice_0002</td>\n      <td>small_bowel</td>\n      <td></td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>case123_day20</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>case123_day20_slice_0099</td>\n      <td>small_bowel</td>\n      <td></td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>case123_day20</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>case123_day20_slice_0099</td>\n      <td>stomach</td>\n      <td></td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>case123_day20</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>case123_day20_slice_0100</td>\n      <td>large_bowel</td>\n      <td></td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>case123_day20</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>case123_day20_slice_0100</td>\n      <td>small_bowel</td>\n      <td></td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>case123_day20</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>case123_day20_slice_0100</td>\n      <td>stomach</td>\n      <td></td>\n      <td>../input/uw-madison-gi-tract-image-segmentatio...</td>\n      <td>case123_day20</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 5.3 Start Inferencing","metadata":{}},{"cell_type":"code","source":"subs = []\nfor day, group in tqdm(sub.groupby(\"days\")):\n    imgs = []\n    for file_name in group.file_name.unique():\n        img = cv2.imread(file_name, cv2.IMREAD_ANYDEPTH)\n        old_size = img.shape[:2]\n        s = int(os.path.basename(file_name).split(\"_\")[1])\n        file_names = [file_name.replace(f\"slice_{s:04d}\", f\"slice_{s + i:04d}\") for i in range(-2, 3)]\n        file_names = [_ for _ in file_names if os.path.exists(_)]\n        imgs = [cv2.imread(file_names[0], cv2.IMREAD_ANYDEPTH)] + [img] + [cv2.imread(file_names[-1], cv2.IMREAD_ANYDEPTH)]\n        \n        new_img = np.stack(imgs, -1)\n        new_img = new_img.astype(np.float32) / new_img.max()\n\n        res = [inference_segmentor(model, new_img)[0] for model in models]\n        res = (sum(res) / len(res)).round().astype(np.uint8)\n        res = cv2.resize(res, old_size[::-1], interpolation = cv2.INTER_NEAREST)\n        for j in range(3):\n            rle = rle_encode(res[...,j])\n            index = fname2index[file_name + classes[j]]\n            sub.loc[index, \"predicted\"] = rle","metadata":{"execution":{"iopub.status.busy":"2022-05-09T09:18:59.247102Z","iopub.execute_input":"2022-05-09T09:18:59.247667Z","iopub.status.idle":"2022-05-09T09:19:03.890284Z","shell.execute_reply.started":"2022-05-09T09:18:59.247630Z","shell.execute_reply":"2022-05-09T09:19:03.889256Z"},"trusted":true},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45fb8b28f155414eb09d2d79d0da85c6"}},"metadata":{}}]},{"cell_type":"markdown","source":"## 5.4 Format submission","metadata":{}},{"cell_type":"code","source":"sub = sub[[\"id\", \"class\", \"predicted\"]]\nsub.to_csv(\"submission.csv\", index = False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-05-09T09:19:09.193695Z","iopub.execute_input":"2022-05-09T09:19:09.193998Z","iopub.status.idle":"2022-05-09T09:19:09.218688Z","shell.execute_reply.started":"2022-05-09T09:19:09.193967Z","shell.execute_reply":"2022-05-09T09:19:09.217291Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"                           id        class predicted\n0    case123_day20_slice_0001  large_bowel          \n1    case123_day20_slice_0001  small_bowel          \n2    case123_day20_slice_0001      stomach          \n3    case123_day20_slice_0002  large_bowel          \n4    case123_day20_slice_0002  small_bowel          \n..                        ...          ...       ...\n295  case123_day20_slice_0099  small_bowel          \n296  case123_day20_slice_0099      stomach          \n297  case123_day20_slice_0100  large_bowel          \n298  case123_day20_slice_0100  small_bowel          \n299  case123_day20_slice_0100      stomach          \n\n[300 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>class</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>case123_day20_slice_0001</td>\n      <td>large_bowel</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>case123_day20_slice_0001</td>\n      <td>small_bowel</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>case123_day20_slice_0001</td>\n      <td>stomach</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>case123_day20_slice_0002</td>\n      <td>large_bowel</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>case123_day20_slice_0002</td>\n      <td>small_bowel</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>case123_day20_slice_0099</td>\n      <td>small_bowel</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>case123_day20_slice_0099</td>\n      <td>stomach</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>case123_day20_slice_0100</td>\n      <td>large_bowel</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>case123_day20_slice_0100</td>\n      <td>small_bowel</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>case123_day20_slice_0100</td>\n      <td>stomach</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 3 columns</p>\n</div>"},"metadata":{}}]}]}